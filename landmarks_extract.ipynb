{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting frames and landmarks from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pymongo import MongoClient\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1730028763.545234  402030 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1730028763.618257  410082 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.107.02), renderer: NVIDIA GeForce RTX 4050 Laptop GPU/PCIe/SSE2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1730028763.682152  410065 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730028763.771491  410076 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730028763.773721  410066 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730028763.773779  410079 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730028763.773781  410076 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730028763.780717  410074 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730028763.788402  410076 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730028763.789894  410071 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "holistic = mp_holistic.Holistic(static_image_mode = False,\n",
    "                                model_complexity = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "connection = MongoClient('localhost', 27017)\n",
    "db = connection['mydb']\n",
    "collection = db['Sign_Language_Final_Data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1730027090.221653  402124 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730027090.317357  402137 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730027090.319724  402125 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730027090.319900  402138 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730027090.322865  402122 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730027090.326819  402138 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730027090.337502  402129 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1730027090.337800  402130 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "cursor = collection.find({})\n",
    "df = pd.DataFrame(list(cursor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>bbox</th>\n",
       "      <th>fps</th>\n",
       "      <th>frame_end</th>\n",
       "      <th>frame_start</th>\n",
       "      <th>instance_id</th>\n",
       "      <th>signer_id</th>\n",
       "      <th>source</th>\n",
       "      <th>split</th>\n",
       "      <th>url</th>\n",
       "      <th>variation_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>is_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>671c624d104a133c1d8d0b1c</td>\n",
       "      <td>book</td>\n",
       "      <td>[385, 37, 885, 720]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>aslbrick</td>\n",
       "      <td>train</td>\n",
       "      <td>http://aslbricks.org/New/ASL-Videos/book.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>v_id_69241</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>671c624d104a133c1d8d0b1d</td>\n",
       "      <td>book</td>\n",
       "      <td>[462, 44, 949, 720]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>signschool</td>\n",
       "      <td>train</td>\n",
       "      <td>https://signstock.blob.core.windows.net/signsc...</td>\n",
       "      <td>0</td>\n",
       "      <td>v_id_07069</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>671c624d104a133c1d8d0b1e</td>\n",
       "      <td>book</td>\n",
       "      <td>[234, 17, 524, 414]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "      <td>startasl</td>\n",
       "      <td>train</td>\n",
       "      <td>https://s3-us-west-1.amazonaws.com/files.start...</td>\n",
       "      <td>0</td>\n",
       "      <td>v_id_07068</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>671c624d104a133c1d8d0b1f</td>\n",
       "      <td>book</td>\n",
       "      <td>[131, 26, 526, 480]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>59</td>\n",
       "      <td>asldeafined</td>\n",
       "      <td>train</td>\n",
       "      <td>https://media.asldeafined.com/vocabulary/14666...</td>\n",
       "      <td>0</td>\n",
       "      <td>v_id_07070</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>671c624d104a133c1d8d0b20</td>\n",
       "      <td>book</td>\n",
       "      <td>[162, 54, 528, 400]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>aslsearch</td>\n",
       "      <td>val</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/book.mp4</td>\n",
       "      <td>0</td>\n",
       "      <td>v_id_07099</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id gloss                 bbox  fps  frame_end  \\\n",
       "0  671c624d104a133c1d8d0b1c  book  [385, 37, 885, 720]   25         -1   \n",
       "1  671c624d104a133c1d8d0b1d  book  [462, 44, 949, 720]   25         -1   \n",
       "2  671c624d104a133c1d8d0b1e  book  [234, 17, 524, 414]   25         -1   \n",
       "3  671c624d104a133c1d8d0b1f  book  [131, 26, 526, 480]   25         -1   \n",
       "4  671c624d104a133c1d8d0b20  book  [162, 54, 528, 400]   25         -1   \n",
       "\n",
       "   frame_start  instance_id  signer_id       source  split  \\\n",
       "0            1            0        118     aslbrick  train   \n",
       "1            1           10         31   signschool  train   \n",
       "2            1           17         36     startasl  train   \n",
       "3            1           22         59  asldeafined  train   \n",
       "4            1           24         12    aslsearch    val   \n",
       "\n",
       "                                                 url  variation_id  \\\n",
       "0       http://aslbricks.org/New/ASL-Videos/book.mp4             0   \n",
       "1  https://signstock.blob.core.windows.net/signsc...             0   \n",
       "2  https://s3-us-west-1.amazonaws.com/files.start...             0   \n",
       "3  https://media.asldeafined.com/vocabulary/14666...             0   \n",
       "4     http://www.aslsearch.com/signs/videos/book.mp4             0   \n",
       "\n",
       "     video_id  is_available  \n",
       "0  v_id_69241          True  \n",
       "1  v_id_07069          True  \n",
       "2  v_id_07068          True  \n",
       "3  v_id_07070          True  \n",
       "4  v_id_07099          True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['_id', 'source', 'url'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>bbox</th>\n",
       "      <th>fps</th>\n",
       "      <th>frame_end</th>\n",
       "      <th>frame_start</th>\n",
       "      <th>instance_id</th>\n",
       "      <th>signer_id</th>\n",
       "      <th>split</th>\n",
       "      <th>variation_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>is_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>[385, 37, 885, 720]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>v_id_69241</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book</td>\n",
       "      <td>[462, 44, 949, 720]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>v_id_07069</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book</td>\n",
       "      <td>[234, 17, 524, 414]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>v_id_07068</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>[131, 26, 526, 480]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>59</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>v_id_07070</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book</td>\n",
       "      <td>[162, 54, 528, 400]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "      <td>v_id_07099</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gloss                 bbox  fps  frame_end  frame_start  instance_id  \\\n",
       "0  book  [385, 37, 885, 720]   25         -1            1            0   \n",
       "1  book  [462, 44, 949, 720]   25         -1            1           10   \n",
       "2  book  [234, 17, 524, 414]   25         -1            1           17   \n",
       "3  book  [131, 26, 526, 480]   25         -1            1           22   \n",
       "4  book  [162, 54, 528, 400]   25         -1            1           24   \n",
       "\n",
       "   signer_id  split  variation_id    video_id  is_available  \n",
       "0        118  train             0  v_id_69241          True  \n",
       "1         31  train             0  v_id_07069          True  \n",
       "2         36  train             0  v_id_07068          True  \n",
       "3         59  train             0  v_id_07070          True  \n",
       "4         12    val             0  v_id_07099          True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['video_id'] = df['video_id'].apply(lambda id: id.replace('v_id_', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>bbox</th>\n",
       "      <th>fps</th>\n",
       "      <th>frame_end</th>\n",
       "      <th>frame_start</th>\n",
       "      <th>instance_id</th>\n",
       "      <th>signer_id</th>\n",
       "      <th>split</th>\n",
       "      <th>variation_id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>is_available</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>[385, 37, 885, 720]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>69241</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book</td>\n",
       "      <td>[462, 44, 949, 720]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>07069</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book</td>\n",
       "      <td>[234, 17, 524, 414]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>07068</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>[131, 26, 526, 480]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>59</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>07070</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book</td>\n",
       "      <td>[162, 54, 528, 400]</td>\n",
       "      <td>25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>val</td>\n",
       "      <td>0</td>\n",
       "      <td>07099</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gloss                 bbox  fps  frame_end  frame_start  instance_id  \\\n",
       "0  book  [385, 37, 885, 720]   25         -1            1            0   \n",
       "1  book  [462, 44, 949, 720]   25         -1            1           10   \n",
       "2  book  [234, 17, 524, 414]   25         -1            1           17   \n",
       "3  book  [131, 26, 526, 480]   25         -1            1           22   \n",
       "4  book  [162, 54, 528, 400]   25         -1            1           24   \n",
       "\n",
       "   signer_id  split  variation_id video_id  is_available  \n",
       "0        118  train             0    69241          True  \n",
       "1         31  train             0    07069          True  \n",
       "2         36  train             0    07068          True  \n",
       "3         59  train             0    07070          True  \n",
       "4         12    val             0    07099          True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11980"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['frame_start'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['frame_end'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train', 'val', 'test']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['split'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8313"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['split'] == 'train').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1414"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['split'] == 'test').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2253"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['split'] == 'val').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gloss'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landmarks(video_path, frame_start, frame_end):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    total_frames = count_frames(video_path)\n",
    "\n",
    "    if frame_end == -1:\n",
    "        frame_end = total_frames - 1\n",
    "\n",
    "    landmarks_sequence = []\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_start)\n",
    "\n",
    "    while cap.isOpened() and frame_start <= frame_end:\n",
    "        current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "\n",
    "        if current_frame > frame_end:\n",
    "            break\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = holistic.process(image_rgb)\n",
    "\n",
    "        frame_landmarks = {}\n",
    "\n",
    "        if results.face_landmarks:\n",
    "            frame_landmarks[\"face\"] = [(lm.x, lm.y, lm.z) for lm in results.face_landmarks.landmark]\n",
    "        if results.left_hand_landmarks:\n",
    "            frame_landmarks[\"left_hand\"] = [(lm.x, lm.y, lm.z) for lm in results.left_hand_landmarks.landmark]\n",
    "        if results.right_hand_landmarks:\n",
    "            frame_landmarks[\"right_hand\"] = [(lm.x, lm.y, lm.z) for lm in results.right_hand_landmarks.landmark]\n",
    "        \n",
    "        landmarks_sequence.append(frame_landmarks)\n",
    "\n",
    "    cap.release()\n",
    "    return landmarks_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   0%|          | 0/11980 [00:00<?, ?it/s]W0000 00:00:1730027111.618326  402130 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "Processing videos:   2%|▏         | 224/11980 [24:37<21:32:37,  6.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m frame_end \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mframe_end\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./kaggle-dataset/videos/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 12\u001b[0m landmarks_sequence \u001b[38;5;241m=\u001b[39m \u001b[43mextract_landmarks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_end\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 25\u001b[0m, in \u001b[0;36mextract_landmarks\u001b[0;34m(video_path, frame_start, frame_end)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     23\u001b[0m image_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m---> 25\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mholistic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m frame_landmarks \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mface_landmarks:\n",
      "File \u001b[0;32m~/miniconda3/envs/twh/lib/python3.12/site-packages/mediapipe/python/solutions/holistic.py:160\u001b[0m, in \u001b[0;36mHolistic.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[1;32m    137\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m         \"enable_segmentation\" is set to true.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark:  \u001b[38;5;66;03m# pytype: disable=attribute-error\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/twh/lib/python3.12/site-packages/mediapipe/python/solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[1;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[1;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[0;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "landmarks_data = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing videos\"):\n",
    "    video_id = row['video_id']\n",
    "    frame_start = row['frame_start']\n",
    "    frame_end = row['frame_end']\n",
    "    video_path = f'./kaggle-dataset/videos/{video_id}.mp4'\n",
    "\n",
    "    landmarks_sequence = extract_landmarks(video_path, frame_start, frame_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# with mp_holistic.Holistic(static_image_mode=False, \n",
    "#                            model_complexity=2, \n",
    "#                            enable_segmentation=True,\n",
    "#                            min_detection_confidence=0.5,\n",
    "#                            min_tracking_confidence=0.5) as holistic:\n",
    "#     while cap.isOpened():\n",
    "#         ret,frame = cap.read()\n",
    "#         if not ret:\n",
    "#             print(\"Ignoring empty camera frame\")\n",
    "#             continue\n",
    "\n",
    "#         frame = cv2.flip(frame, 1)\n",
    "        \n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image.flags.writeable = False\n",
    "\n",
    "#         results = holistic.process(image)\n",
    "\n",
    "#         image.flags.writeable = True\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#         if results.face_landmarks:\n",
    "#              mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS)\n",
    "#         # if results.pose_landmarks:\n",
    "#         #      mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "#         if results.left_hand_landmarks:\n",
    "#              mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "#         if results.right_hand_landmarks:\n",
    "#              mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "#         cv2.imshow('TEST', image)\n",
    "\n",
    "#         if cv2.waitKey(5) & 0xFF == 27:  # Press 'Esc' to exit\n",
    "#                 break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
